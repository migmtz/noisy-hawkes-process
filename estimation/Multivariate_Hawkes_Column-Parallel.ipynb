{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52db1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats\n",
    "from collections import deque\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import norm, inv, det\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b607f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multivariate_exponential_hawkes(object):\n",
    "    \"\"\"\n",
    "    Multivariate Hawkes process with exponential kernel. No events nor initial conditions considered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, alpha, beta, max_jumps=None, max_time=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : array_like\n",
    "            Baseline intensity vector. mu.shape[0] must coincide with shapes for alpha and beta.\n",
    "        alpha : array_like\n",
    "            Interaction factors matrix. Must be a square array with alpha.shape[0] coinciding with mu and beta.\n",
    "        beta : array_like\n",
    "            Decay factor matrix. Must be either an array. When corresponding to decay for each process i, it must\n",
    "            be of shape (number_of_process, 1), or a square array. beta.shape[0] must coincide with mu and alpha.\n",
    "        max_jumps : float, optional\n",
    "            Maximal number of jumps. The default is None.\n",
    "        max_time : float, optional\n",
    "            Maximal time horizon. The default is None.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        nb_processes : int\n",
    "            Number of dimensions.\n",
    "        timestamps : list of tuple (float, int)\n",
    "            List of simulated events and their marks.\n",
    "        intensity_jumps : array of float\n",
    "            Array containing all intensities at each jump. It includes the baseline intensities mu.\n",
    "        simulated : bool\n",
    "            Parameter that marks if a process has been already been simulated,\n",
    "            or if its event times have been initialized.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # We must begin by verifying that the process is a point process. In other words, that the number of\n",
    "        # points in any bounded interval is a.s. finite. For this, we have to verify that the spectral radius of\n",
    "        # the matrix alpha/beta (term by term) is <1.\n",
    "\n",
    "        beta_radius = np.copy(beta)\n",
    "        beta_radius[beta_radius == 0] = 1\n",
    "        spectral_radius = np.max(np.abs(np.linalg.eig(np.abs(alpha) / beta_radius)[0]))\n",
    "\n",
    "        if spectral_radius >= 1:\n",
    "            # raise ValueError(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius))\n",
    "            warnings.warn(\"Spectral radius is %s, which makes the process unstable.\" % (spectral_radius),RuntimeWarning)\n",
    "        self.mu = mu.reshape((alpha.shape[0], 1))\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_jumps = max_jumps\n",
    "        self.max_time = max_time\n",
    "\n",
    "        self.nb_processes = self.mu.shape[0]\n",
    "        self.count = np.zeros(self.nb_processes, dtype=int)\n",
    "\n",
    "        self.timestamps = [(0.0, 0)]\n",
    "        self.intensity_jumps = np.copy(mu)\n",
    "\n",
    "        self.simulated = False\n",
    "\n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "        Auxiliary function to check if already simulated and, if not, which simulation to launch.\n",
    "\n",
    "        Simulation follows Ogata's adapted thinning algorithm. Upper bound obtained by the positive-part process.\n",
    "\n",
    "        Works with both self-exciting and self-regulating processes.\n",
    "\n",
    "        To launch simulation either self.max_jumps or self.max_time must be other than None, so the algorithm knows when to stop.\n",
    "        \"\"\"\n",
    "        if not self.simulated:\n",
    "            if self.max_jumps is not None and self.max_time is None:\n",
    "                self.simulate_jumps()\n",
    "            elif self.max_time is not None and self.max_jumps is None:\n",
    "                self.simulate_time()\n",
    "            else:\n",
    "                print(\"Either max_jumps or max_time must be given.\")\n",
    "            self.simulated = True\n",
    "\n",
    "        else:\n",
    "            print(\"Process already simulated\")\n",
    "\n",
    "    def simulate_jumps(self):\n",
    "        \"\"\"\n",
    "        Simulation is done until the maximal number of jumps (self.max_jumps) is attained.\n",
    "        \"\"\"\n",
    "        flag = 0\n",
    "        t = 0\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag < self.max_jumps:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1, np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            if type_event < self.nb_processes:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                flag += 1\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.max_time = self.timestamps[-1][0]\n",
    "        # Important to add the max_time for plotting and being consistent.\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def simulate_time(self):\n",
    "        \"\"\"\n",
    "        Simulation is done for a window [0, T] (T = self.max_time) is attained.\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        flag = t < self.max_time\n",
    "\n",
    "        auxiliary_alpha = np.where(self.alpha > 0, self.alpha, 0)\n",
    "        auxiliary_ij = np.zeros((self.nb_processes, self.nb_processes))\n",
    "        auxiliary_intensity = np.copy(self.mu)\n",
    "\n",
    "        ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "        while flag:\n",
    "\n",
    "            upper_intensity = np.sum(auxiliary_intensity)\n",
    "\n",
    "            previous_t = t\n",
    "            t += np.random.exponential(1 / upper_intensity)\n",
    "\n",
    "            # ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - self.timestamps[-1][0])))\n",
    "            ij_intensity = np.multiply(ij_intensity, np.exp(-self.beta * (t - previous_t)))\n",
    "            candidate_intensities = self.mu + np.sum(ij_intensity, axis=1, keepdims=True)\n",
    "            pos_candidate = np.maximum(candidate_intensities, 0) / upper_intensity\n",
    "            type_event = np.random.multinomial(1,\n",
    "                                               np.concatenate((pos_candidate.squeeze(), np.array([0.0])))).argmax()\n",
    "            flag = t < self.max_time\n",
    "            if type_event < self.nb_processes and flag:\n",
    "                self.timestamps += [(t, type_event + 1)]\n",
    "                ij_intensity[:, type_event] += self.alpha[:, type_event]\n",
    "                self.intensity_jumps = np.c_[\n",
    "                    self.intensity_jumps, self.mu + np.sum(ij_intensity, axis=1, keepdims=True)]\n",
    "\n",
    "                auxiliary_ij = np.multiply(auxiliary_ij, np.exp(-self.beta * (t - self.timestamps[-2][0])))\n",
    "                auxiliary_ij[:, type_event] += auxiliary_alpha[:, type_event]\n",
    "                auxiliary_intensity = self.mu + np.sum(auxiliary_ij, axis=1, keepdims=True)\n",
    "\n",
    "                self.count[type_event] += 1\n",
    "\n",
    "        self.timestamps += [(self.max_time, 0)]\n",
    "\n",
    "    def plot_intensity(self, ax=None, plot_N=True, where=10):\n",
    "        \"\"\"\n",
    "        Plot intensity function. If plot_N is True, plots also step functions N^i([0,t]).\n",
    "        The parameter ax allows to plot the intensity function in a previously created plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : array of Axes, optional.\n",
    "            If None, method will generate own figure.\n",
    "            Otherwise, will use given axes. Must be array of shape (2,K) if plot_N = True, or (K,) if plot_N = False\n",
    "        plot_N : bool, optional.\n",
    "            Whether we plot the step function N^i or not.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.simulated:\n",
    "            print(\"Simulate first\")\n",
    "\n",
    "        else:\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            if plot_N:\n",
    "                jumps_plot = [[0] for i in range(self.nb_processes)]\n",
    "                if ax is None:\n",
    "                    fig, ax = plt.subplots(2, self.nb_processes, sharex=True)\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                elif isinstance(ax[0,0], matplotlib.axes.Axes):\n",
    "                    ax1 = ax[0, :]\n",
    "                    ax2 = ax[1, :]\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (2, number of processes+1)\"\n",
    "            else:\n",
    "                if ax is None:\n",
    "                    fig, ax1 = plt.subplots(1, self.nb_processes)\n",
    "                elif isinstance(ax, matplotlib.axes.Axes) or isinstance(ax, np.ndarray):\n",
    "                    ax1 = ax\n",
    "                else:\n",
    "                    return \"ax is the wrong shape. It should be (number of processes+1,)\"\n",
    "\n",
    "            times = [0, self.timestamps[1][0]]\n",
    "            intensities = np.array([[self.mu[i, 0], self.mu[i, 0]] for i in range(self.nb_processes)])\n",
    "\n",
    "            ij_intensity = np.zeros((self.nb_processes, self.nb_processes))\n",
    "\n",
    "            step = 100\n",
    "            # print(\"here\", self.timestamps[len(self.timestamps)])\n",
    "\n",
    "            for i in range(1, len(self.timestamps[1:where])):\n",
    "                # On commence par mettre à jour la matrice lambda^{ij}\n",
    "                ij_intensity = np.multiply(ij_intensity,\n",
    "                                           np.exp(-self.beta * (self.timestamps[i][0] - self.timestamps[i - 1][0])))\n",
    "                # On enregistre le saut d'intensité de l'évenement, pour son type.\n",
    "                ij_intensity[:, self.timestamps[i][1]-1] += self.alpha[:, self.timestamps[i][1]-1]\n",
    "\n",
    "                # On définit la fonction à tracer entre T_n et T_{n+1}\n",
    "                func = lambda x: self.mu + np.matmul(\n",
    "                    np.multiply(ij_intensity, np.exp(-self.beta * (x - self.timestamps[i][0]))),\n",
    "                                np.ones((self.nb_processes, 1)))\n",
    "\n",
    "                # On enregistre la division de temps et les sauts\n",
    "                interval_t = np.linspace(self.timestamps[i][0], self.timestamps[i + 1][0], step)\n",
    "                times += interval_t.tolist()\n",
    "\n",
    "                intensities = np.concatenate((intensities, np.array(list(map(func, interval_t))).squeeze().T ), axis=1)\n",
    "                if plot_N:\n",
    "                    jumps_plot[self.timestamps[i][1]-1] += [self.timestamps[i][0] for t in range(2)]\n",
    "\n",
    "            for i in range(self.nb_processes):\n",
    "                ax1[i].plot(times, intensities[i], label=\"Underlying intensity\", c=\"#1f77b4\", linestyle=\"--\")\n",
    "                ax1[i].plot(times, np.maximum(intensities[i], 0), label=\"Conditional intensity\", c='r')\n",
    "                # ax1[i].plot([i for i,j in self.timestamps[:-1]], self.intensity_jumps[i,:], c='k', alpha=0.5)\n",
    "\n",
    "            ax1[0].legend()\n",
    "\n",
    "            if plot_N:\n",
    "                for i in range(self.nb_processes):\n",
    "                    jumps_plot[i] += [times[-1]]\n",
    "                    ax2[i].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"r\", label=\"Process #%s\"%(i+1))\n",
    "                    # ax2[i].set_ylim(ax2[i].get_ylim())\n",
    "                    for j in range(self.nb_processes):\n",
    "                        if j != i:\n",
    "                            ax2[j].plot(jumps_plot[i], [t for t in range(len(jumps_plot[i])//2) for j in range(2)], c=\"#1f77b4\", alpha=0.5)\n",
    "\n",
    "                    ax2[i].legend()\n",
    "\n",
    "    def plot_heatmap(self, ax=None):\n",
    "        \"\"\"\n",
    "        This function allows to observe the heatmap where each cell {ij} corresponds to the value {alpha/beta} from that interaction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax : .axes.Axes, optional.\n",
    "            If None, method will generate own ax.\n",
    "            Otherwise, will use given ax.\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        else:\n",
    "            ax = ax\n",
    "        beta_heat = np.copy(self.beta)\n",
    "        beta_heat[beta_heat == 0] = 1\n",
    "        heat_matrix = self.alpha/beta_heat\n",
    "\n",
    "        hex_list = ['#FF3333', '#FFFFFF', '#33FF49']\n",
    "\n",
    "        ax = sns.heatmap(heat_matrix, cmap=get_continuous_cmap(hex_list), center=0, ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b5953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_periodogram(w, tList):\n",
    "    max_time = tList[-1][0]\n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    \n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    J_w = np.array([np.sum([np.exp(2j * np.pi * w * t) for t in i]) for i in dimensional_times]).reshape((dim, 1))\n",
    "    return (1/max_time) * J_w @ np.conj(J_w.T)\n",
    "\n",
    "\n",
    "def multivariate_spectral_noised_density(w, theta):\n",
    "    mu, alpha, beta, noise = theta\n",
    "    dim = mu.shape[0]\n",
    "    mean_matrix = np.identity(dim) * (inv(np.identity(dim) - alpha + 1e-12) @ mu)\n",
    "    \n",
    "    fourier_matrix = alpha * beta / (beta + 2j * np.pi * w)\n",
    "    spectral_matrix = inv(np.identity(dim) - fourier_matrix)\n",
    "    return np.conj(spectral_matrix) @ mean_matrix @ (spectral_matrix.T) + noise * np.identity(dim)\n",
    "\n",
    "\n",
    "def spectral_multivariate_noised_ll(theta, periodogram, K, max_time):\n",
    "    dim = int(np.sqrt(theta.shape[0]) - 1)\n",
    "    theta_mid = theta[:-1]\n",
    "    theta_aux = (theta_mid[:dim].reshape((dim, 1)), theta_mid[dim:-dim].reshape((dim, dim)), theta_mid[-dim:].reshape((dim, 1)), theta[-1])\n",
    "    f_matrixes = [multivariate_spectral_noised_density(j/max_time, theta_aux) for j in range(1, K+1)]\n",
    "    ll = np.sum([np.trace(inv(f_matrixes[i]) @ periodogram[i]) + np.log(det(f_matrixes[i])) for i in range(0, K)])\n",
    "    return (1/max_time) * ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c62932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_periodogram(w, tList):\n",
    "    max_time = tList[-1][0]\n",
    "    dim = int(np.max(np.array(tList)[:, 1]))\n",
    "    \n",
    "    dimensional_times = [[t for t,i in tList if i == j] for j in range(1, dim+1)]\n",
    "    \n",
    "    J_w = np.array([np.sum([np.exp(2j * np.pi * w * t) for t in i]) for i in dimensional_times]).reshape((dim, 1))\n",
    "    return (1/max_time) * J_w @ np.conj(J_w.T)\n",
    "\n",
    "\n",
    "def multivariate_spectral_noised_column(w, theta):\n",
    "    mu, alpha_aux, beta, noise = theta\n",
    "    alpha = np.hstack((alpha_aux.reshape((2, 1)), np.zeros((2,1))))\n",
    "    #beta = np.array([beta_aux, 0]).reshape((2, 1))\n",
    "    dim = mu.shape[0]\n",
    "    m_1 = mu[0,0]/(1-alpha[0,0])\n",
    "    m_2 = mu[1,0] + m_1 * alpha[1,0]\n",
    "    \n",
    "    aux_11 = (beta[0,0]**2 + (2 * np.pi * w)**2)/(((1- alpha[0,0])* beta[0,0])**2 + (2 * np.pi * w)**2)\n",
    "\n",
    "    f_11 = m_1 * aux_11 + noise\n",
    "    f_12 = m_1 * aux_11 * (alpha[1,0] * beta[1,0])/(beta[1,0] + 2j * np.pi * w)\n",
    "    f_21 = m_1 * aux_11 * (alpha[1,0] * beta[1,0])/(beta[1,0] - 2j * np.pi * w)\n",
    "    f_22 = m_1 * aux_11 * ((alpha[1,0] * beta[1,0])**2)/(beta[1,0]**2 + (2 * np.pi * w)**2) + m_2 + noise\n",
    "    return np.array([[f_11, f_12], [f_21, f_22]])\n",
    "\n",
    "\n",
    "def spectral_multivariate_noised_ll_column(theta, periodogram, K, max_time):\n",
    "    dim = 2\n",
    "    #theta_mid = theta[:-1]\n",
    "    theta_aux = (np.array(theta[:dim]).reshape((dim, 1)), \n",
    "                 np.array(theta[dim:dim+2]).reshape((dim, 1)), \n",
    "                 np.array(theta[dim+2:-1]).reshape((dim,1)), \n",
    "                 theta[-1])\n",
    "    f_matrixes = [multivariate_spectral_noised_column(j/max_time, theta_aux) for j in range(1, K+1)]\n",
    "    ll = np.sum([np.trace(inv(f_matrixes[i]) @ periodogram[i]) + np.log(det(f_matrixes[i])) for i in range(0, K)])\n",
    "    return (1/max_time) * ll.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8f5b8",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba779ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral radius: 0.5\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([[1.0],\n",
    "               [1.0]])\n",
    "\n",
    "alpha = np.array([[0.5, 0.0],\n",
    "                  [0.4, 0.0]])\n",
    "\n",
    "beta = np.array([[1.0],\n",
    "                 [1.3]])\n",
    "\n",
    "noise = 0.5\n",
    "\n",
    "print(\"Spectral radius:\", np.max(np.abs(np.linalg.eig(alpha)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13655143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------------------|\n",
      "|------------------"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool, cpu_count\n",
    "# Reduced model estimation (parallel)\n",
    "\n",
    "max_time = 3000\n",
    "repetitions = 50\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    init = np.random.rand(7) + np.r_[.5, .5, 0., 0., .5, .5, .5]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll_column,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(4) as p:\n",
    "    estimations_max = np.array(p.map(job, range(repetitions)))\n",
    "print(estimations_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0011f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Full model estimation (parallel)\n",
    "max_time = 3000\n",
    "repetitions = 50\n",
    "# estimations_max = np.zeros((repetitions, 5))\n",
    "\n",
    "\n",
    "bounds = [(1e-16, None), (1e-16, None), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), (1e-16, 1-1e-16), \n",
    "          (1e-16, None), (1e-16, None), (1e-16, None)]\n",
    "\n",
    "dim = 2\n",
    "\n",
    "def job(it):\n",
    "    np.random.seed(it)\n",
    "    hp = multivariate_exponential_hawkes(mu, alpha * beta, beta, max_time=max_time)\n",
    "    hp.simulate()\n",
    "    hp_times = hp.timestamps\n",
    "\n",
    "    pp = multivariate_exponential_hawkes(noise * np.ones((2,1)), 0*alpha, beta, max_time=max_time)\n",
    "    pp.simulate()\n",
    "    pp_times = pp.timestamps\n",
    "\n",
    "    idx = np.argsort(pp_times[1:-1] + hp_times, axis=0)[:, 0]\n",
    "    parasited_times = np.array(pp_times[1:-1] + hp_times)[idx]\n",
    "    K = int(parasited_times.shape[0])\n",
    "    init = np.random.rand(9)/2 + np.r_[.75, .75, 0., 0., 0., 0., .75, .75, .75]\n",
    "    \n",
    "    periodogram = [multivariate_periodogram(j/max_time, parasited_times) for j in range(1, K+1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    res = minimize(spectral_multivariate_noised_ll,\n",
    "                   init, tol=1e-16,\n",
    "                   method=\"L-BFGS-B\", jac=None,\n",
    "                   args=(periodogram, K, max_time),\n",
    "                   bounds=bounds, options={\"disp\":False})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('-', end='')\n",
    "    # print(res.x)\n",
    "\n",
    "    return res.x\n",
    "print('|'+'-'*repetitions+'|')\n",
    "print('|', end='')\n",
    "with Pool(cpu_count()-1) as p:\n",
    "    estimations = np.array(p.map(job, range(repetitions)))\n",
    "print('|\\n Done')\n",
    "#print(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d142f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "explanation = \"Estimations for Scenario 1 (Column).\"\n",
    "explanation += \" First is explanation, second is estimations in reduced model,\"\n",
    "explanation += \" third is estimations in full model.\"\n",
    "explanation += \" Dimensions (repetitions, parameters).\"\n",
    "explanation\n",
    "toSave = (explanation, estimations_max, estimations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
